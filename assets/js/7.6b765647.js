(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{360:function(t,a,s){t.exports=s.p+"assets/img/image-11.000ebc31.png"},361:function(t,a,s){t.exports=s.p+"assets/img/image-12.3b613e7e.png"},362:function(t,a,s){t.exports=s.p+"assets/img/image-13.30d17195.png"},363:function(t,a,s){t.exports=s.p+"assets/img/image-14.3d2f5006.png"},364:function(t,a,s){t.exports=s.p+"assets/img/image-15.5f98c2b3.png"},365:function(t,a,s){t.exports=s.p+"assets/img/image-16.6e2a5278.png"},366:function(t,a,s){t.exports=s.p+"assets/img/image-17.c0f5f9ba.png"},367:function(t,a,s){t.exports=s.p+"assets/img/image-18.4c3c8ca5.png"},368:function(t,a,s){t.exports=s.p+"assets/img/image-19.6a34ab85.png"},369:function(t,a,s){t.exports=s.p+"assets/img/image-20.c0172a80.png"},370:function(t,a,s){t.exports=s.p+"assets/img/image-21.9d617797.png"},371:function(t,a,s){t.exports=s.p+"assets/img/image-22.9adaad0c.png"},372:function(t,a,s){t.exports=s.p+"assets/img/image-23.482693ab.png"},373:function(t,a,s){t.exports=s.p+"assets/img/image-24.16d3cc70.png"},374:function(t,a,s){t.exports=s.p+"assets/img/image-25.b60456cd.png"},375:function(t,a,s){t.exports=s.p+"assets/img/image-26.4befc3da.png"},474:function(t,a,s){"use strict";s.r(a);var i=s(1),e=Object(i.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"앙상블"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#앙상블"}},[t._v("#")]),t._v(" 앙상블")]),t._v(" "),a("p",[t._v("알고리즘 종류")]),t._v(" "),a("p",[t._v("단일 알고리즘을 적당히 조합하여 단일 알고리즘보다 성능이 향상되는 것을 기대하는 알고리즘")]),t._v(" "),a("p",[t._v("특정 알고리즘이 모든 데이터 셋에서 항상 좋다고 보장 할 수 없고")]),t._v(" "),a("p",[t._v("특정 데이터 셋에서 성능이 좋은 알고리즘이 다르다")]),t._v(" "),a("h2",{attrs:{id:"ensemble-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ensemble-learning"}},[t._v("#")]),t._v(" Ensemble learning")]),t._v(" "),a("p",[t._v("여러 명의 집단지성이 한 사람보다 어려운 문제를 풀기 좋은 이유와 비슷")]),t._v(" "),a("p",[a("img",{attrs:{src:s(360),alt:"alt text"}})]),t._v(" "),a("p",[t._v("오버피팅 감소 효과")]),t._v(" "),a("p",[t._v("개별 모델 성능이 잘 안나올 때 효과가 있다")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Bagging")])]),t._v(" "),a("li",[a("p",[t._v("Voting")])]),t._v(" "),a("li",[a("p",[t._v("Boosting")])]),t._v(" "),a("li",[a("p",[t._v("Stacking")])])]),t._v(" "),a("h3",{attrs:{id:"bagging"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bagging"}},[t._v("#")]),t._v(" Bagging")]),t._v(" "),a("p",[t._v("데이터 셈플링")]),t._v(" "),a("p",[t._v("중복을 허용 하여 같은 알고리즘과 중복을 허용하여")]),t._v(" "),a("p",[t._v("오버피팅 방지 효과적")]),t._v(" "),a("p",[a("img",{attrs:{src:s(361),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"pasting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pasting"}},[t._v("#")]),t._v(" Pasting")]),t._v(" "),a("p",[t._v("중복 X")]),t._v(" "),a("p",[t._v("보통은 Bagging을 많이 사용함")]),t._v(" "),a("p",[a("img",{attrs:{src:s(362),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"voing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#voing"}},[t._v("#")]),t._v(" Voing")]),t._v(" "),a("p",[t._v("알고리즘 모델을 조합")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("하드 보팅: 다수결 원칙")])]),t._v(" "),a("li",[a("p",[t._v("소프트 보팅: 평균을 적용")])])]),t._v(" "),a("p",[a("img",{attrs:{src:s(363),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"보깅-vs-보팅"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#보깅-vs-보팅"}},[t._v("#")]),t._v(" 보깅 VS 보팅")]),t._v(" "),a("p",[a("img",{attrs:{src:s(364),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"boosting"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#boosting"}},[t._v("#")]),t._v(" Boosting")]),t._v(" "),a("p",[t._v("여러개의 분류기가 순차적으로 학습과 예측을 진행")]),t._v(" "),a("p",[t._v("오버피팅 가능성이 있어 잘 컨트롤 해야함")]),t._v(" "),a("p",[a("img",{attrs:{src:s(365),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"stacking"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#stacking"}},[t._v("#")]),t._v(" Stacking")]),t._v(" "),a("p",[t._v("여러 모델들을 활용해 각각의 예측 결과를 도출한 뒤 그 예측 결과를 결합해서 최종 예측 결과를 만들어 내는 것")]),t._v(" "),a("p",[t._v("오버 피팅에 위험")]),t._v(" "),a("p",[t._v("Cross validation 기반으로 많이 쓰임")]),t._v(" "),a("p",[t._v("굉장히 많은 baseline 모델이 필요하다. 시간이 필요하다")]),t._v(" "),a("p",[a("img",{attrs:{src:s(366),alt:"alt text"}})]),t._v(" "),a("h2",{attrs:{id:"tree-algorithms"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tree-algorithms"}},[t._v("#")]),t._v(" Tree algorithms")]),t._v(" "),a("h3",{attrs:{id:"decision-tress-impurity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#decision-tress-impurity"}},[t._v("#")]),t._v(" Decision Tress: Impurity")]),t._v(" "),a("p",[t._v("해당 노드 안에서 섞여 있는 정도가 높을수록 복잡성이 높고, 덜 섞여 있을수록 복잡성이 낮다.")]),t._v(" "),a("p",[a("img",{attrs:{src:s(367),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"gini-index"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gini-index"}},[t._v("#")]),t._v(" Gini Index")]),t._v(" "),a("p",[t._v("불순도 측정 지표 데이터 통계적 분산정도 정량화 표현한 값")]),t._v(" "),a("p",[a("img",{attrs:{src:s(368),alt:"alt text"}})]),t._v(" "),a("p",[t._v("misclassfication error: 불순도 측정은 가능하나, 미분이 불가능하여 자주 쓰이지는 않는다")]),t._v(" "),a("h3",{attrs:{id:"graphviz"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#graphviz"}},[t._v("#")]),t._v(" Graphviz")]),t._v(" "),a("p",[a("img",{attrs:{src:s(369),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"gradient-boosting-pseudo-code"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gradient-boosting-pseudo-code"}},[t._v("#")]),t._v(" Gradient Boosting: Pseudo code")]),t._v(" "),a("p",[a("img",{attrs:{src:s(370),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"xgboost"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#xgboost"}},[t._v("#")]),t._v(" XGboost")]),t._v(" "),a("p",[a("img",{attrs:{src:s(371),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"lightgbm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lightgbm"}},[t._v("#")]),t._v(" LightGBM")]),t._v(" "),a("p",[a("img",{attrs:{src:s(372),alt:"alt text"}})]),t._v(" "),a("h3",{attrs:{id:"catboost"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#catboost"}},[t._v("#")]),t._v(" Catboost")]),t._v(" "),a("p",[t._v("범주형에서 많이 쓰임")]),t._v(" "),a("p",[a("img",{attrs:{src:s(373),alt:"alt text"}})]),t._v(" "),a("h2",{attrs:{id:"tab-net"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tab-net"}},[t._v("#")]),t._v(" Tab net")]),t._v(" "),a("p",[a("img",{attrs:{src:s(374),alt:"alt text"}})]),t._v(" "),a("p",[t._v("논문에서 발표됨")]),t._v(" "),a("p",[t._v("정형데이터를 위한 딥러닝 모델")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("전처리 과정이 필요하지 않음")])]),t._v(" "),a("li",[a("p",[t._v("정형 데이터에 대해서 기존의 Decision Tree-based gradient boosting(xgboost, lgbm, catboost)와 같은 모델에 비해 신경망 모델은 아직 성능이 안정적이지 못함. 두 구조의 장점을 모두 갖는 신경망 모델")])]),t._v(" "),a("li",[a("p",[t._v("Feature selection, interpretability(local, global)가 가능한 신경망 모델, 설명가능한 모델")])]),t._v(" "),a("li",[a("p",[t._v("Feature 값을 예측하는 Unsuprevised pretrain 단계를 적용하여 상당한 성능 향상을 보여줌")])])]),t._v(" "),a("p",[t._v("순차적인 어텐션을 사용하여 각 의사 결정 단계에서 추론한 특징을 선택하여 학습 능력이 가낭 두드러진 특징을 사용")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("기존의 특징 선택과 모델 학습 과정이 나누어 진걸 한번에 가능")])]),t._v(" "),a("li",[a("p",[t._v("이로 인해 어떤 특징이 중요한지 설명이 가능하다.")])])]),t._v(" "),a("p",[a("img",{attrs:{src:s(375),alt:"alt text"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/.image-27.png",alt:"alt text"}})])])}),[],!1,null,null,null);a.default=e.exports}}]);